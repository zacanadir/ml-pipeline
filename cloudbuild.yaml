
options:
  logging: CLOUD_LOGGING_ONLY  # ensures builds work without specifying logs bucket

steps:
# 1️⃣ Build Docker image
- name: 'gcr.io/cloud-builders/docker'
  id: 'build-image'
  args: ['build', '-t', 'us-central1-docker.pkg.dev/$PROJECT_ID/myrepo/ml-pipeline:$SHORT_SHA', '.']

# 2️⃣ Push Docker image
- name: 'gcr.io/cloud-builders/docker'
  id: 'push-image'
  args: ['push', 'us-central1-docker.pkg.dev/$PROJECT_ID/myrepo/ml-pipeline:$SHORT_SHA']

# 3️⃣ Run tests (CI)
- name: 'gcr.io/cloud-builders/docker'
  id: 'run-tests'
  args:
    - 'run'
    - '--rm'
    - 'us-central1-docker.pkg.dev/$PROJECT_ID/myrepo/ml-pipeline:$SHORT_SHA'
    - '-m'
    - 'pytest'
    - '-q'
    - 'tests/test_pipeline.py'

# 4️⃣ Submit pipeline job to Vertex AI (CD)
- name: 'us-central1-docker.pkg.dev/$PROJECT_ID/myrepo/ml-pipeline:$SHORT_SHA'
  id: 'submit-pipeline-job'
  entrypoint: 'bash'
  args:
    - '-c'
    - |
      python pipelines/pipeline_job.py \
        --project $PROJECT_ID \
        --region $_REGION \
        --pipeline_root $_PIPELINE_ROOT \
        --display_name "ml-pipeline-$SHORT_SHA" \
        --commit_id $SHORT_SHA


images:
  - 'us-central1-docker.pkg.dev/$PROJECT_ID/myrepo/ml-pipeline:$SHORT_SHA'

substitutions:
  _REGION: us-central1
  _PIPELINE_ROOT: gs://taxi_model028/pipeline_root
